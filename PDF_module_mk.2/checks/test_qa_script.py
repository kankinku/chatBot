#!/usr/bin/env python3
"""
í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸ë‹µë³€ ìŠ¤í¬ë¦½íŠ¸ (ì‹¤ì œ ì§ˆë¬¸ ì„¸íŠ¸ ê¸°ë°˜)
"""

import sys
import os
import time
from datetime import datetime

sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from main import PDFQASystem

class PDFQATestSuite:
    """PDF QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""
    
    def __init__(self):
        self.system = PDFQASystem()
        self.test_results = []
        self.test_questions = [
            {"question": "ì„¸ì¢…ì‹œì˜ 2020ë…„ ê¸°ì¤€ êµí†µìˆ˜ë‹¨ ë¶„ë‹´ë¥ ì—ì„œ ìŠ¹ìš©ì°¨ê°€ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ì€?", "expected_keywords": ["45.4%", "ìŠ¹ìš©ì°¨"], "description": "ì„¸ì¢…ì‹œ ìŠ¹ìš©ì°¨ êµí†µìˆ˜ë‹¨ ë¶„ë‹´ë¥  í™•ì¸"},
            {"question": "ì„¸ì¢…ì‹œì˜ ë²„ìŠ¤ êµí†µìˆ˜ë‹¨ ë¶„ë‹´ë¥ ì€ ì–¼ë§ˆì¸ê°€ìš”?", "expected_keywords": ["7.3%", "ë²„ìŠ¤"], "description": "ì„¸ì¢…ì‹œ ë²„ìŠ¤ êµí†µìˆ˜ë‹¨ ë¶„ë‹´ë¥  í™•ì¸"},
            {"question": "ì„¸ì¢…ì‹œ ì‹œë¯¼ë“¤ì˜ ëŒ€ì¤‘êµí†µ ë¶ˆë§Œì¡±ë„ëŠ”?", "expected_keywords": ["61%", "ë¶ˆë§Œì¡±"], "description": "ì„¸ì¢…ì‹œ ì‹œë¯¼ ëŒ€ì¤‘êµí†µ ë¶ˆë§Œì¡±ë„ í™•ì¸"},
            {"question": "ì„¸ì¢…ì‹œì˜ êµí†µ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ì„¤ëª…í•˜ê³  ìˆë‚˜ìš”?", "expected_keywords": ["êµí†µì§€ì˜¥", "ë³‘ëª©í˜„ìƒ", "ìê°€ìš© ì˜ì¡´ë„"], "description": "ì„¸ì¢…ì‹œ êµí†µ ë¬¸ì œ ì„¤ëª… í™•ì¸"},
            {"question": "BRT ì „ìš©ì°¨ë¡œê°€ ì–´ë–¤ ë¬¸ì œë¥¼ ì¼ìœ¼í‚¤ê³  ìˆë‚˜ìš”?", "expected_keywords": ["êµí†µ ì²´ì¦", "ì•…í™”", "ì•…ìˆœí™˜"], "description": "BRT ì „ìš©ì°¨ë¡œ ë¬¸ì œì  í™•ì¸"},
            {"question": "íŒ€ëª…ì´ ë¬´ì—‡ì¸ê°€ìš”?", "expected_keywords": ["í¬ë²„ìŠ¤", "í¬ë²„ìŠ¤íŒ€"], "description": "íŒ€ëª… í™•ì¸"},
            {"question": "íŒ€ì¥ì˜ ì´ë¦„ì€?", "expected_keywords": ["ì›ë™ì˜"], "description": "íŒ€ì¥ ì´ë¦„ í™•ì¸"},
            {"question": "íŒ€ì›ì€ ëª‡ ëª…ì¸ê°€ìš”?", "expected_keywords": ["4ëª…", "4"], "description": "íŒ€ì› ìˆ˜ í™•ì¸"},
            {"question": "ì œì•ˆëª…ì€ ë¬´ì—‡ì¸ê°€ìš”?", "expected_keywords": ["AI ê¸°ë°˜ ì„¸ì¢…ì‹œ êµí†µ ë°ì´í„° í•´ì„ í”Œë«í¼"], "description": "ì œì•ˆëª… í™•ì¸"},
            {"question": "íŒ€ì¥ì˜ ì—°ë½ì²˜ëŠ”?", "expected_keywords": ["010-9984-8639"], "description": "íŒ€ì¥ ì—°ë½ì²˜ í™•ì¸"},
            {"question": "íŒ€ì¥ì˜ ì´ë©”ì¼ì€?", "expected_keywords": ["wdyoung11@g.hongik.ac.kr"], "description": "íŒ€ì¥ ì´ë©”ì¼ í™•ì¸"},
            {"question": "íŒ€ì›ë“¤ì˜ ì†Œì†ì€?", "expected_keywords": ["í™ìµëŒ€í•™êµ"], "description": "íŒ€ì› ì†Œì† í™•ì¸"},
            {"question": "í‚¤ì›Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?", "expected_keywords": ["êµí†µ ë°ì´í„°", "ë°ì´í„° ì‹œê°í™”", "AI ë¶„ì„", "ì‹œë¯¼ ì°¸ì—¬", "ì •ì±… ì œì•ˆ"], "description": "í‚¤ì›Œë“œ í™•ì¸"},
            {"question": "ê°œë°œ ë°°ê²½ì€ ë¬´ì—‡ì¸ê°€ìš”?", "expected_keywords": ["ì‹œë¯¼ ì£¼ë„í˜•", "ìŠ¤ë§ˆíŠ¸ ì‹œí‹°", "ë°ì´í„° í™œìš©"], "description": "ê°œë°œ ë°°ê²½ í™•ì¸"},
        ]
    
    def check_answer_accuracy(self, answer: str, expected_keywords: list) -> tuple:
        answer_lower = answer.lower()
        found_keywords = [kw for kw in expected_keywords if kw.lower() in answer_lower]
        accuracy = len(found_keywords) / len(expected_keywords) if expected_keywords else 0
        return accuracy, found_keywords
    
    def run_single_test(self, test_item: dict) -> dict:
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸: {test_item['description']}")
        print(f"ì§ˆë¬¸: {test_item['question']}")
        start_time = time.time()
        result = self.system.ask_question(test_item['question'])
        response_time = time.time() - start_time
        accuracy, found_keywords = self.check_answer_accuracy(result['answer'], test_item['expected_keywords'])
        return {
            "question": test_item['question'],
            "description": test_item['description'],
            "answer": result['answer'],
            "confidence": result['confidence_score'],
            "expected_keywords": test_item['expected_keywords'],
            "found_keywords": found_keywords,
            "accuracy": accuracy,
            "response_time": response_time,
            "timestamp": datetime.now().isoformat(),
        }
    
    def run_full_test_suite(self, iterations: int = 1) -> list:
        print("="*70)
        print("ğŸ§ª PDF QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*70)
        print(f"í…ŒìŠ¤íŠ¸ ë¬¸ì„œ: data í´ë”ì˜ PDF íŒŒì¼ë“¤")
        print(f"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ìˆ˜: {len(self.test_questions)}ê°œ")
        print(f"ë°˜ë³µ íšŸìˆ˜: {iterations}íšŒ")
        print("="*70)
        print("\nğŸ”§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        if not self.system.initialize_components():
            print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return []
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        all_results = []
        for iteration in range(iterations):
            if iterations > 1:
                print(f"\nğŸ”„ {iteration + 1}íšŒì°¨ í…ŒìŠ¤íŠ¸")
                print("-" * 50)
            for i, test_item in enumerate(self.test_questions, 1):
                print(f"\n[{i}/{len(self.test_questions)}]", end=" ")
                res = self.run_single_test(test_item)
                res['iteration'] = iteration + 1
                all_results.append(res)
                time.sleep(0.5)
        self.test_results = all_results
        return all_results
    
    def analyze_results(self) -> dict:
        if not self.test_results:
            return {}
        total = len(self.test_results)
        avg_accuracy = sum(r['accuracy'] for r in self.test_results) / total
        avg_confidence = sum(r['confidence'] for r in self.test_results) / total
        avg_response_time = sum(r['response_time'] for r in self.test_results) / total
        excellent = sum(1 for r in self.test_results if r['accuracy'] >= 0.8)
        good = sum(1 for r in self.test_results if 0.5 <= r['accuracy'] < 0.8)
        poor = sum(1 for r in self.test_results if r['accuracy'] < 0.5)
        failed = [r for r in self.test_results if r['accuracy'] < 0.5]
        return {
            "total_tests": total,
            "avg_accuracy": avg_accuracy,
            "avg_confidence": avg_confidence,
            "avg_response_time": avg_response_time,
            "excellent_count": excellent,
            "good_count": good,
            "poor_count": poor,
            "failed_tests": failed,
        }
    
    def print_summary(self) -> None:
        analysis = self.analyze_results()
        if not analysis:
            print("âŒ ë¶„ì„í•  í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        print("\n" + "="*70)
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("="*70)
        print(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {analysis['total_tests']}ê°œ")
        print(f"í‰ê·  ì •í™•ë„: {analysis['avg_accuracy']:.2%}")
        print(f"í‰ê·  ì‹ ë¢°ë„: {analysis['avg_confidence']:.2f}")
        print(f"í‰ê·  ì‘ë‹µì‹œê°„: {analysis['avg_response_time']:.2f}ì´ˆ")
        print(f"\nğŸ“ˆ ì„±ëŠ¥ ë¶„í¬:")
        print(f"  âœ… ìš°ìˆ˜ (80% ì´ìƒ): {analysis['excellent_count']}ê°œ ({analysis['excellent_count']/analysis['total_tests']:.1%})")
        print(f"  âš ï¸ ë³´í†µ (50-80%): {analysis['good_count']}ê°œ ({analysis['good_count']/analysis['total_tests']:.1%})")
        print(f"  âŒ ë¯¸í¡ (50% ë¯¸ë§Œ): {analysis['poor_count']}ê°œ ({analysis['poor_count']/analysis['total_tests']:.1%})")
        if analysis['failed_tests']:
            print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ({len(analysis['failed_tests'])}ê°œ):")
            for test in analysis['failed_tests']:
                print(f"  - {test['description']}: {test['accuracy']:.1%}")
        print(f"\nğŸ¯ ì „ì²´ ì‹œìŠ¤í…œ í‰ê°€:")
        if analysis['avg_accuracy'] >= 0.8:
            print("âœ… ìš°ìˆ˜ - ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤")
        elif analysis['avg_accuracy'] >= 0.6:
            print("âš ï¸ ì–‘í˜¸ - ì¼ë¶€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")
        else:
            print("âŒ ë¯¸í¡ - ì‹œìŠ¤í…œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")

def main():
    import argparse
    parser = argparse.ArgumentParser(description="PDF QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--iterations", "-i", type=int, default=1, help="í…ŒìŠ¤íŠ¸ ë°˜ë³µ íšŸìˆ˜")
    parser.add_argument("--save", "-s", action="store_true", help="ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥")
    args = parser.parse_args()
    suite = PDFQATestSuite()
    try:
        suite.run_full_test_suite(iterations=args.iterations)
        suite.print_summary()
        if args.save:
            import json
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"test_results_{timestamp}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(suite.test_results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {filename}")
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()


