#!/usr/bin/env python3
"""
í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸ë‹µë³€ ìŠ¤í¬ë¦½íŠ¸
ìƒì„±í•œ í…ŒìŠ¤íŠ¸ PDFì— ëŒ€í•œ ëª…í™•í•œ ì§ˆë¬¸ë“¤ì„ ë°˜ë³µ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import time
from datetime import datetime

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from korean_qa import KoreanQASystem

class PDFQATestSuite:
    """PDF QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""
    
    def __init__(self):
        """í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì´ˆê¸°í™”"""
        self.system = KoreanQASystem()
        self.test_results = []
        
        # í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸-ì •ë‹µ ìŒ ì •ì˜
        self.test_questions = [
            {
                "question": "íšŒì‚¬ëª…ì´ ë­ì•¼?",
                "expected_keywords": ["í…Œí¬ë…¸ ì†”ë£¨ì…˜ì¦ˆ", "í…Œí¬ë…¸ì†”ë£¨ì…˜ì¦ˆ"],
                "description": "íšŒì‚¬ëª… í™•ì¸"
            },
            {
                "question": "ì„¤ë¦½ì—°ë„ëŠ” ì–¸ì œì•¼?",
                "expected_keywords": ["2020", "2020ë…„"],
                "description": "ì„¤ë¦½ì—°ë„ í™•ì¸"
            },
            {
                "question": "ì§ì›ì´ ëª‡ ëª…ì´ì•¼?",
                "expected_keywords": ["150", "150ëª…"],
                "description": "ì§ì› ìˆ˜ í™•ì¸"
            },
            {
                "question": "ë³¸ì‚¬ê°€ ì–´ë””ì— ìˆì–´?",
                "expected_keywords": ["ì„œìš¸", "ê°•ë‚¨êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ"],
                "description": "ë³¸ì‚¬ ìœ„ì¹˜ í™•ì¸"
            },
            {
                "question": "í´ë¼ìš°ë“œë§¤ë‹ˆì € Pro ê°€ê²©ì€?",
                "expected_keywords": ["50ë§Œì›", "ì›” 50ë§Œì›"],
                "description": "ì œí’ˆ ê°€ê²© í™•ì¸"
            },
            {
                "question": "ë°ì´í„°ë¶„ì„ í”Œë«í¼ì€ ì–¸ì œ ì¶œì‹œëì–´?",
                "expected_keywords": ["2022ë…„ 1ì›”", "2022", "1ì›”"],
                "description": "ì œí’ˆ ì¶œì‹œì¼ í™•ì¸"
            },
            {
                "question": "ê°œë°œíŒ€ì¥ì´ ëˆ„êµ¬ì•¼?",
                "expected_keywords": ["ê¹€ì² ìˆ˜"],
                "description": "íŒ€ì¥ ì •ë³´ í™•ì¸"
            },
            {
                "question": "2023ë…„ ë§¤ì¶œì•¡ì´ ì–¼ë§ˆì•¼?",
                "expected_keywords": ["180ì–µ", "180ì–µì›"],
                "description": "ë§¤ì¶œì•¡ í™•ì¸"
            },
            {
                "question": "ì „í™”ë²ˆí˜¸ê°€ ë­ì•¼?",
                "expected_keywords": ["02-1234-5678"],
                "description": "ì—°ë½ì²˜ í™•ì¸"
            },
            {
                "question": "ISO ì¸ì¦ì„ ì–¸ì œ ë°›ì•˜ì–´?",
                "expected_keywords": ["2022", "2022ë…„", "ISO 27001"],
                "description": "ì¸ì¦ ì •ë³´ í™•ì¸"
            },
            {
                "question": "íŠ¹í—ˆë¥¼ ëª‡ ê±´ ë³´ìœ í•˜ê³  ìˆì–´?",
                "expected_keywords": ["12ê±´", "12", "íŠ¹í—ˆ"],
                "description": "íŠ¹í—ˆ ë³´ìœ  ê±´ìˆ˜ í™•ì¸"
            },
            {
                "question": "ì£¼ìš” ê³ ê°ì‚¬ëŠ” ì–´ë””ì•¼?",
                "expected_keywords": ["ì‚¼ì„±ì „ì", "LGì „ì", "ë„¤ì´ë²„"],
                "description": "ê³ ê°ì‚¬ ì •ë³´ í™•ì¸"
            }
        ]
    
    def check_answer_accuracy(self, answer: str, expected_keywords: list) -> tuple:
        """ë‹µë³€ ì •í™•ì„± ê²€ì‚¬"""
        answer_lower = answer.lower()
        found_keywords = []
        
        for keyword in expected_keywords:
            if keyword.lower() in answer_lower:
                found_keywords.append(keyword)
        
        accuracy = len(found_keywords) / len(expected_keywords) if expected_keywords else 0
        return accuracy, found_keywords
    
    def run_single_test(self, test_item: dict) -> dict:
        """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸: {test_item['description']}")
        print(f"ì§ˆë¬¸: {test_item['question']}")
        
        start_time = time.time()
        result = self.system.ask_question(test_item['question'])
        response_time = time.time() - start_time
        
        accuracy, found_keywords = self.check_answer_accuracy(
            result['answer'], 
            test_item['expected_keywords']
        )
        
        test_result = {
            "question": test_item['question'],
            "description": test_item['description'],
            "answer": result['answer'],
            "confidence": result['confidence'],
            "expected_keywords": test_item['expected_keywords'],
            "found_keywords": found_keywords,
            "accuracy": accuracy,
            "response_time": response_time,
            "timestamp": datetime.now().isoformat()
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"ë‹µë³€: {result['answer']}")
        print(f"ì‹ ë¢°ë„: {result['confidence']:.2f}")
        print(f"ì •í™•ë„: {accuracy:.2%} ({len(found_keywords)}/{len(test_item['expected_keywords'])})")
        print(f"ë°œê²¬ëœ í‚¤ì›Œë“œ: {found_keywords}")
        print(f"ì‘ë‹µì‹œê°„: {response_time:.2f}ì´ˆ")
        
        # ì •í™•ë„ì— ë”°ë¥¸ í‰ê°€
        if accuracy >= 0.8:
            print("âœ… ìš°ìˆ˜")
        elif accuracy >= 0.5:
            print("âš ï¸ ë³´í†µ")
        else:
            print("âŒ ë¯¸í¡")
        
        return test_result
    
    def run_full_test_suite(self, iterations: int = 1) -> list:
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰"""
        print("="*70)
        print("ğŸ§ª PDF QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*70)
        print(f"í…ŒìŠ¤íŠ¸ ë¬¸ì„œ: í…Œí¬ë…¸ ì†”ë£¨ì…˜ì¦ˆ íšŒì‚¬ì •ë³´")
        print(f"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ìˆ˜: {len(self.test_questions)}ê°œ")
        print(f"ë°˜ë³µ íšŸìˆ˜: {iterations}íšŒ")
        print("="*70)
        
        all_results = []
        
        for iteration in range(iterations):
            if iterations > 1:
                print(f"\nğŸ”„ {iteration + 1}íšŒì°¨ í…ŒìŠ¤íŠ¸")
                print("-" * 50)
            
            iteration_results = []
            
            for i, test_item in enumerate(self.test_questions, 1):
                print(f"\n[{i}/{len(self.test_questions)}]", end=" ")
                test_result = self.run_single_test(test_item)
                test_result['iteration'] = iteration + 1
                iteration_results.append(test_result)
                
                # ì ì‹œ ëŒ€ê¸° (ì‹œìŠ¤í…œ ì•ˆì •ì„±)
                time.sleep(0.5)
            
            all_results.extend(iteration_results)
        
        self.test_results = all_results
        return all_results
    
    def analyze_results(self) -> dict:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        if not self.test_results:
            return {}
        
        # ì „ì²´ í†µê³„
        total_tests = len(self.test_results)
        avg_accuracy = sum(r['accuracy'] for r in self.test_results) / total_tests
        avg_confidence = sum(r['confidence'] for r in self.test_results) / total_tests
        avg_response_time = sum(r['response_time'] for r in self.test_results) / total_tests
        
        # ì •í™•ë„ë³„ ë¶„í¬
        excellent_count = sum(1 for r in self.test_results if r['accuracy'] >= 0.8)
        good_count = sum(1 for r in self.test_results if 0.5 <= r['accuracy'] < 0.8)
        poor_count = sum(1 for r in self.test_results if r['accuracy'] < 0.5)
        
        # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸
        failed_tests = [r for r in self.test_results if r['accuracy'] < 0.5]
        
        analysis = {
            "total_tests": total_tests,
            "avg_accuracy": avg_accuracy,
            "avg_confidence": avg_confidence,
            "avg_response_time": avg_response_time,
            "excellent_count": excellent_count,
            "good_count": good_count,
            "poor_count": poor_count,
            "failed_tests": failed_tests
        }
        
        return analysis
    
    def print_summary(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        analysis = self.analyze_results()
        
        if not analysis:
            print("âŒ ë¶„ì„í•  í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n" + "="*70)
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("="*70)
        
        print(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {analysis['total_tests']}ê°œ")
        print(f"í‰ê·  ì •í™•ë„: {analysis['avg_accuracy']:.2%}")
        print(f"í‰ê·  ì‹ ë¢°ë„: {analysis['avg_confidence']:.2f}")
        print(f"í‰ê·  ì‘ë‹µì‹œê°„: {analysis['avg_response_time']:.2f}ì´ˆ")
        
        print(f"\nğŸ“ˆ ì„±ëŠ¥ ë¶„í¬:")
        print(f"  âœ… ìš°ìˆ˜ (80% ì´ìƒ): {analysis['excellent_count']}ê°œ ({analysis['excellent_count']/analysis['total_tests']:.1%})")
        print(f"  âš ï¸ ë³´í†µ (50-80%): {analysis['good_count']}ê°œ ({analysis['good_count']/analysis['total_tests']:.1%})")
        print(f"  âŒ ë¯¸í¡ (50% ë¯¸ë§Œ): {analysis['poor_count']}ê°œ ({analysis['poor_count']/analysis['total_tests']:.1%})")
        
        if analysis['failed_tests']:
            print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ({len(analysis['failed_tests'])}ê°œ):")
            for test in analysis['failed_tests']:
                print(f"  - {test['description']}: {test['accuracy']:.1%}")
        
        # ì „ì²´ í‰ê°€
        print(f"\nğŸ¯ ì „ì²´ ì‹œìŠ¤í…œ í‰ê°€:")
        if analysis['avg_accuracy'] >= 0.8:
            print("âœ… ìš°ìˆ˜ - ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤")
        elif analysis['avg_accuracy'] >= 0.6:
            print("âš ï¸ ì–‘í˜¸ - ì¼ë¶€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")
        else:
            print("âŒ ë¯¸í¡ - ì‹œìŠ¤í…œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="PDF QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--iterations", "-i", type=int, default=1, 
                       help="í…ŒìŠ¤íŠ¸ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ê°’: 1)")
    parser.add_argument("--save", "-s", action="store_true",
                       help="ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥")
    
    args = parser.parse_args()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_suite = PDFQATestSuite()
    
    try:
        test_suite.run_full_test_suite(iterations=args.iterations)
        test_suite.print_summary()
        
        # ê²°ê³¼ ì €ì¥
        if args.save:
            import json
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"test_results_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(test_suite.test_results, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {filename}")
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
