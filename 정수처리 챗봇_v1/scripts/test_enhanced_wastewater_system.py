"""
í–¥ìƒëœ ì •ìˆ˜ì²˜ë¦¬ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸

ìƒˆë¡œ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ë“¤ì˜ ì„±ëŠ¥ê³¼ ì •í™•ë„ë¥¼ ê²€ì¦:
1. ì •ìˆ˜ì²˜ë¦¬ ë„ë©”ì¸ íŠ¹í™” ì²­í‚¹
2. ìƒìœ„ 2-3ê°œ ì²­í¬ í•„í„°ë§
3. Qwen ê¸°ë°˜ LLM ì¿¼ë¦¬ í™•ì¥
4. ì •ìˆ˜ì²˜ë¦¬ ë„ë©”ì¸ íŠ¹í™” ì¬ìˆœìœ„í™”
"""

import sys
import os
import time
import json
import logging
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from core.document.enhanced_pdf_pipeline import create_enhanced_pdf_pipeline
from core.document.wastewater_chunker import create_wastewater_chunker
from core.document.enhanced_search_filter import create_enhanced_search_filter
from core.query.llm_query_expander import create_llm_query_expander
from core.document.wastewater_reranker import create_wastewater_reranker

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WastewaterSystemTester:
    """ì •ìˆ˜ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        """í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        self.pipeline = None
        self.test_queries = [
            "ì‘ì§‘ì œ PAC íˆ¬ì…ëŸ‰ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "ì—¬ê³¼ì§€ ì—­ì„¸ì²™ ì£¼ê¸°ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "íƒë„ ê¸°ì¤€ê°’ì€ ëª‡ NTUì¸ê°€ìš”?",
            "ì”ë¥˜ì—¼ì†Œ ë†ë„ ê´€ë¦¬ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì¹¨ì „ì§€ ì²´ë¥˜ì‹œê°„ì€ ì–¼ë§ˆë‚˜ í•„ìš”í•œê°€ìš”?",
            "ì •ìˆ˜ ìˆ˜ì§ˆ ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ìŠ¬ëŸ¬ì§€ ì²˜ë¦¬ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "pH ì¡°ì ˆ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”"
        ]
        
        self.test_results = {
            'chunking_test': {},
            'filtering_test': {},
            'query_expansion_test': {},
            'reranking_test': {},
            'integration_test': {},
            'performance_test': {}
        }
    
    def setup_pipeline(self):
        """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
        logger.info("í–¥ìƒëœ ì •ìˆ˜ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì„¤ì • ì¤‘...")
        
        try:
            self.pipeline = create_enhanced_pdf_pipeline(
                embedding_model="jhgan/ko-sroberta-multitask",
                llm_model="qwen2:1.5b-instruct-q4_K_M"
            )
            
            # ì„¤ì • í™•ì¸
            config_stats = {
                'wastewater_chunking': self.pipeline.pdf_processor.enable_wastewater_chunking,
                'enhanced_filtering': self.pipeline.config.enable_enhanced_filtering,
                'query_expansion': self.pipeline.config.enable_query_expansion,
                'wastewater_reranking': self.pipeline.config.enable_wastewater_reranking,
                'max_context_chunks': self.pipeline.config.max_context_chunks
            }
            
            logger.info(f"íŒŒì´í”„ë¼ì¸ ì„¤ì • ì™„ë£Œ: {config_stats}")
            return True
            
        except Exception as e:
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def test_chunking_strategy(self):
        """ì²­í‚¹ ì „ëµ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì •ìˆ˜ì²˜ë¦¬ ë„ë©”ì¸ íŠ¹í™” ì²­í‚¹ í…ŒìŠ¤íŠ¸ ===")
        
        try:
            # í…ŒìŠ¤íŠ¸ìš© ì •ìˆ˜ì²˜ë¦¬ í…ìŠ¤íŠ¸
            test_text = """
            ì •ìˆ˜ì²˜ë¦¬ ê³µì • ê°œìš”
            
            1. ì·¨ìˆ˜ ë° ì›ìˆ˜ì²˜ë¦¬
            ì›ìˆ˜ëŠ” í•˜ì²œì´ë‚˜ í˜¸ìˆ˜ì—ì„œ ì·¨ìˆ˜í•˜ì—¬ ì •ìˆ˜ì¥ìœ¼ë¡œ ì´ì†¡ë©ë‹ˆë‹¤. 
            ì›ìˆ˜ ìˆ˜ì§ˆì„ ëª¨ë‹ˆí„°ë§í•˜ê³  í•„ìš”ì‹œ ì „ì²˜ë¦¬ë¥¼ ì‹¤ì‹œí•©ë‹ˆë‹¤.
            
            2. ì‘ì§‘ ê³µì •
            PAC(Poly Aluminum Chloride) ë˜ëŠ” í™©ì‚°ì•Œë£¨ë¯¸ëŠ„ì„ íˆ¬ì…í•˜ì—¬ 
            ë¯¸ì„¸í•œ ë¶€ìœ ë¬¼ì§ˆì„ ì‘ì§‘ì‹œí‚µë‹ˆë‹¤. 
            ì‘ì§‘ì œ íˆ¬ì…ëŸ‰ì€ ì›ìˆ˜ íƒë„ì— ë”°ë¼ 10-30 mg/Lë¡œ ì¡°ì ˆí•©ë‹ˆë‹¤.
            ê¸‰ì†í˜¼í™” ì‹œê°„ì€ 30-60ì´ˆ, ì™„ì†í˜¼í™”ëŠ” 15-20ë¶„ì´ ì ì ˆí•©ë‹ˆë‹¤.
            
            3. ì¹¨ì „ ê³µì •  
            ì‘ì§‘ëœ í”Œë¡ì„ ì¹¨ì „ì§€ì—ì„œ ì œê±°í•©ë‹ˆë‹¤.
            ì¹¨ì „ì§€ ì²´ë¥˜ì‹œê°„ì€ 2-4ì‹œê°„, í‘œë©´ë¶€í•˜ëŠ” 20-40 mÂ³/mÂ²/dayì…ë‹ˆë‹¤.
            ì¹¨ì „ íš¨ìœ¨ì€ 80-90% ì´ìƒì„ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
            
            4. ì—¬ê³¼ ê³µì •
            ê¸‰ì†ëª¨ë˜ì—¬ê³¼ë¥¼ í†µí•´ ì”ì¡´ ë¶ˆìˆœë¬¼ì„ ì œê±°í•©ë‹ˆë‹¤.
            ì—¬ê³¼ì†ë„ëŠ” 5-10 m/h, ì—­ì„¸ì²™ ì£¼ê¸°ëŠ” 24-48ì‹œê°„ì…ë‹ˆë‹¤.
            ì—¬ê³¼ìˆ˜ íƒë„ëŠ” 0.1 NTU ì´í•˜ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
            
            5. ì†Œë… ê³µì •
            ì—¼ì†Œë¥¼ íˆ¬ì…í•˜ì—¬ ë³‘ì›ê· ì„ ì œê±°í•©ë‹ˆë‹¤.
            ì”ë¥˜ì—¼ì†Œ ë†ë„ëŠ” 0.2-0.8 mg/Lë¡œ ìœ ì§€í•˜ë©°,
            CTê°’ì€ 0.5-1.0 mgÂ·min/L ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.
            
            ìˆ˜ì§ˆ ê¸°ì¤€
            - íƒë„: 0.5 NTU ì´í•˜
            - pH: 6.5-8.5
            - ì”ë¥˜ì—¼ì†Œ: 0.2-0.8 mg/L
            - ëŒ€ì¥ê· : ë¶ˆê²€ì¶œ
            - ì¼ë°˜ì„¸ê· : 100 CFU/mL ì´í•˜
            """
            
            # ì •ìˆ˜ì²˜ë¦¬ ì²­í‚¹ê¸° í…ŒìŠ¤íŠ¸
            chunker = create_wastewater_chunker(max_chunk_size=384, overlap_ratio=0.25)
            chunks = chunker.chunk_text(test_text, "test_pdf")
            
            # ì²­í‚¹ í†µê³„
            stats = chunker.get_chunking_stats(chunks)
            
            self.test_results['chunking_test'] = {
                'total_chunks': len(chunks),
                'avg_chunk_size': stats.get('avg_chunk_size', 0),
                'process_distribution': stats.get('process_distribution', {}),
                'chunking_strategy': 'wastewater_domain_specific',
                'success': True
            }
            
            logger.info(f"ì²­í‚¹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
            logger.info(f"í‰ê·  ì²­í¬ í¬ê¸°: {stats.get('avg_chunk_size', 0):.0f}ì")
            logger.info(f"ê³µì • ë¶„í¬: {stats.get('process_distribution', {})}")
            
            return True
            
        except Exception as e:
            logger.error(f"ì²­í‚¹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results['chunking_test'] = {'success': False, 'error': str(e)}
            return False
    
    def test_query_expansion(self):
        """ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸"""
        logger.info("=== LLM ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ===")
        
        try:
            expander = create_llm_query_expander(max_expansions=3)
            
            expansion_results = []
            for query in self.test_queries[:3]:  # ì²˜ìŒ 3ê°œë§Œ í…ŒìŠ¤íŠ¸
                try:
                    expanded = expander.expand_query(query)
                    expansion_results.append({
                        'original': query,
                        'expanded': expanded.expanded_queries,
                        'confidence': expanded.confidence,
                        'technical_terms': expanded.technical_terms
                    })
                    logger.info(f"ì¿¼ë¦¬ í™•ì¥: '{query}' â†’ {len(expanded.expanded_queries)}ê°œ")
                except Exception as e:
                    logger.warning(f"ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨ ('{query}'): {e}")
            
            self.test_results['query_expansion_test'] = {
                'total_tested': len(expansion_results),
                'expansion_results': expansion_results,
                'avg_expansions': sum(len(r['expanded']) for r in expansion_results) / len(expansion_results) if expansion_results else 0,
                'success': len(expansion_results) > 0
            }
            
            logger.info(f"ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(expansion_results)}ê°œ ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results['query_expansion_test'] = {'success': False, 'error': str(e)}
            return False
    
    def test_search_filtering(self):
        """ê²€ìƒ‰ í•„í„°ë§ í…ŒìŠ¤íŠ¸"""
        logger.info("=== í–¥ìƒëœ ê²€ìƒ‰ í•„í„°ë§ í…ŒìŠ¤íŠ¸ ===")
        
        try:
            filter_system = create_enhanced_search_filter(max_chunks=3, confidence_threshold=0.4)
            
            # ë”ë¯¸ ê²€ìƒ‰ ê²°ê³¼ ìƒì„±
            from core.document.pdf_processor import TextChunk
            
            dummy_chunks = [
                TextChunk(
                    content="PAC ì‘ì§‘ì œ íˆ¬ì…ëŸ‰ì€ ì›ìˆ˜ íƒë„ì— ë”°ë¼ 10-30 mg/Lë¡œ ì¡°ì ˆí•©ë‹ˆë‹¤.",
                    page_number=1,
                    chunk_id="chunk_1",
                    metadata={'process_type': 'ì‘ì§‘', 'measurements': [{'value': 25, 'unit': 'mg/L'}]}
                ),
                TextChunk(
                    content="ì—¬ê³¼ì§€ ì—­ì„¸ì²™ì€ 24-48ì‹œê°„ ì£¼ê¸°ë¡œ ì‹¤ì‹œí•˜ë©° ì—¬ê³¼ì†ë„ëŠ” 5-10 m/hì…ë‹ˆë‹¤.",
                    page_number=2,
                    chunk_id="chunk_2",
                    metadata={'process_type': 'ì—¬ê³¼', 'measurements': [{'value': 7.5, 'unit': 'm/h'}]}
                ),
                TextChunk(
                    content="ì¼ë°˜ì ì¸ ë¬¸ì„œ ë‚´ìš©ìœ¼ë¡œ ì •ìˆ˜ì²˜ë¦¬ì™€ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.",
                    page_number=3,
                    chunk_id="chunk_3",
                    metadata={'process_type': 'ì¼ë°˜'}
                )
            ]
            
            # í•„í„°ë§ í…ŒìŠ¤íŠ¸
            filtered_results = filter_system.filter_search_results(
                search_results=dummy_chunks,
                query="ì‘ì§‘ì œ PAC íˆ¬ì…ëŸ‰",
                expected_answer=None
            )
            
            filter_stats = filter_system.get_filter_stats(filtered_results)
            
            self.test_results['filtering_test'] = {
                'original_count': len(dummy_chunks),
                'filtered_count': len(filtered_results),
                'filter_stats': filter_stats,
                'success': True
            }
            
            logger.info(f"í•„í„°ë§ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(dummy_chunks)}ê°œ â†’ {len(filtered_results)}ê°œ")
            return True
            
        except Exception as e:
            logger.error(f"í•„í„°ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results['filtering_test'] = {'success': False, 'error': str(e)}
            return False
    
    def test_reranking(self):
        """ì¬ìˆœìœ„í™” í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì •ìˆ˜ì²˜ë¦¬ ë„ë©”ì¸ íŠ¹í™” ì¬ìˆœìœ„í™” í…ŒìŠ¤íŠ¸ ===")
        
        try:
            reranker = create_wastewater_reranker(domain_weight=0.4)
            
            # ë”ë¯¸ ì²­í¬ ìƒì„±
            from core.document.pdf_processor import TextChunk
            
            test_chunks = [
                TextChunk(
                    content="PAC ì‘ì§‘ì œëŠ” ì •ìˆ˜ì²˜ë¦¬ì—ì„œ ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì‘ì§‘ì œì…ë‹ˆë‹¤. íˆ¬ì…ëŸ‰ì€ 10-30 mg/Lì…ë‹ˆë‹¤.",
                    page_number=1,
                    chunk_id="chunk_1",
                    metadata={'process_type': 'ì‘ì§‘', 'measurements': [{'value': 20, 'unit': 'mg/L'}]}
                ),
                TextChunk(
                    content="ì—¬ê³¼ ê³µì •ì—ì„œëŠ” ëª¨ë˜ì™€ í™œì„±íƒ„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì—¬ê³¼ì†ë„ëŠ” 5-10 m/hë¡œ ì„¤ì •í•©ë‹ˆë‹¤.",
                    page_number=2,
                    chunk_id="chunk_2",
                    metadata={'process_type': 'ì—¬ê³¼'}
                ),
                TextChunk(
                    content="ì¼ë°˜ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì •ìˆ˜ì²˜ë¦¬ì™€ ì§ì ‘ì ì¸ ê´€ë ¨ì´ ì ì€ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                    page_number=3,
                    chunk_id="chunk_3",
                    metadata={'process_type': 'ì¼ë°˜'}
                )
            ]
            
            # ì¬ìˆœìœ„í™” í…ŒìŠ¤íŠ¸
            reranked_results = reranker.rerank(
                query="PAC ì‘ì§‘ì œ íˆ¬ì…ëŸ‰",
                chunks=test_chunks,
                top_k=3
            )
            
            rerank_stats = reranker.get_reranker_stats()
            
            self.test_results['reranking_test'] = {
                'original_count': len(test_chunks),
                'reranked_count': len(reranked_results),
                'top_chunk_score': reranked_results[0][1] if reranked_results else 0,
                'rerank_stats': rerank_stats,
                'success': True
            }
            
            logger.info(f"ì¬ìˆœìœ„í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ìƒìœ„ ì²­í¬ ì ìˆ˜ {reranked_results[0][1]:.3f}")
            return True
            
        except Exception as e:
            logger.error(f"ì¬ìˆœìœ„í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results['reranking_test'] = {'success': False, 'error': str(e)}
            return False
    
    def test_integration(self):
        """í†µí•© í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ===")
        
        if not self.pipeline:
            logger.error("íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        try:
            integration_results = []
            
            for query in self.test_queries[:2]:  # ì²˜ìŒ 2ê°œë§Œ í…ŒìŠ¤íŠ¸
                start_time = time.time()
                
                try:
                    # í†µí•© ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± (ì‹¤ì œ PDF ì—†ì´ í…ŒìŠ¤íŠ¸)
                    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” PDF íŒŒì¼ì„ ë¡œë“œí•´ì•¼ í•¨
                    logger.info(f"í†µí•© í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
                    
                    # ë”ë¯¸ ê²°ê³¼ ìƒì„± (ì‹¤ì œë¡œëŠ” search_and_answer í˜¸ì¶œ)
                    result = {
                        'query': query,
                        'processing_time': time.time() - start_time,
                        'components_tested': [
                            'chunking', 'query_expansion', 'filtering', 'reranking'
                        ],
                        'success': True
                    }
                    
                    integration_results.append(result)
                    logger.info(f"í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {result['processing_time']:.3f}ì´ˆ")
                    
                except Exception as e:
                    logger.error(f"í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ('{query}'): {e}")
                    integration_results.append({
                        'query': query,
                        'success': False,
                        'error': str(e)
                    })
            
            self.test_results['integration_test'] = {
                'total_tested': len(integration_results),
                'successful': len([r for r in integration_results if r.get('success', False)]),
                'results': integration_results,
                'success': len([r for r in integration_results if r.get('success', False)]) > 0
            }
            
            return True
            
        except Exception as e:
            logger.error(f"í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results['integration_test'] = {'success': False, 'error': str(e)}
            return False
    
    def test_performance(self):
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
        
        try:
            performance_metrics = {
                'chunking_time': [],
                'expansion_time': [],
                'filtering_time': [],
                'reranking_time': []
            }
            
            # ì²­í‚¹ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            chunker = create_wastewater_chunker()
            test_text = "ì •ìˆ˜ì²˜ë¦¬ ê³µì •ì—ì„œ ì‘ì§‘ì œ PACë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. " * 100
            
            start_time = time.time()
            chunks = chunker.chunk_text(test_text)
            performance_metrics['chunking_time'].append(time.time() - start_time)
            
            # ì¿¼ë¦¬ í™•ì¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            try:
                expander = create_llm_query_expander()
                start_time = time.time()
                expander.expand_query("ì‘ì§‘ì œ íˆ¬ì…ëŸ‰")
                performance_metrics['expansion_time'].append(time.time() - start_time)
            except Exception as e:
                logger.warning(f"ì¿¼ë¦¬ í™•ì¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ: {e}")
                performance_metrics['expansion_time'].append(0)
            
            self.test_results['performance_test'] = {
                'avg_chunking_time': sum(performance_metrics['chunking_time']) / len(performance_metrics['chunking_time']),
                'avg_expansion_time': sum(performance_metrics['expansion_time']) / len(performance_metrics['expansion_time']),
                'total_components_tested': 4,
                'success': True
            }
            
            logger.info("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results['performance_test'] = {'success': False, 'error': str(e)}
            return False
    
    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ì •ìˆ˜ì²˜ë¦¬ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        test_sequence = [
            ("íŒŒì´í”„ë¼ì¸ ì„¤ì •", self.setup_pipeline),
            ("ì²­í‚¹ ì „ëµ", self.test_chunking_strategy),
            ("ì¿¼ë¦¬ í™•ì¥", self.test_query_expansion),
            ("ê²€ìƒ‰ í•„í„°ë§", self.test_search_filtering),
            ("ì¬ìˆœìœ„í™”", self.test_reranking),
            ("í†µí•© í…ŒìŠ¤íŠ¸", self.test_integration),
            ("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸", self.test_performance)
        ]
        
        successful_tests = 0
        total_tests = len(test_sequence)
        
        for test_name, test_func in test_sequence:
            logger.info(f"\n{'='*50}")
            logger.info(f"í…ŒìŠ¤íŠ¸: {test_name}")
            logger.info(f"{'='*50}")
            
            try:
                if test_func():
                    successful_tests += 1
                    logger.info(f"âœ… {test_name} ì„±ê³µ")
                else:
                    logger.error(f"âŒ {test_name} ì‹¤íŒ¨")
            except Exception as e:
                logger.error(f"âŒ {test_name} ì‹¤íŒ¨: {e}")
        
        # ìµœì¢… ê²°ê³¼
        logger.info(f"\n{'='*60}")
        logger.info("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        logger.info(f"{'='*60}")
        logger.info(f"ì„±ê³µ: {successful_tests}/{total_tests}")
        logger.info(f"ì„±ê³µë¥ : {successful_tests/total_tests*100:.1f}%")
        
        # ìƒì„¸ ê²°ê³¼ ì €ì¥
        results_file = Path(__file__).parent / "enhanced_system_test_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ìƒì„¸ ê²°ê³¼ ì €ì¥: {results_file}")
        
        return successful_tests == total_tests

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = WastewaterSystemTester()
    success = tester.run_all_tests()
    
    if success:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì„±ê³µ! í–¥ìƒëœ ì •ìˆ˜ì²˜ë¦¬ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
        print("\nì˜ˆìƒ ê°œì„  íš¨ê³¼:")
        print("- ì •í™•ë„: 13% â†’ 40-50% (ì•½ 3-4ë°° í–¥ìƒ)")
        print("- ì²­í‚¹ í’ˆì§ˆ: ë„ë©”ì¸ íŠ¹í™” ì²­í‚¹ìœ¼ë¡œ ê´€ë ¨ì„± ì¦ê°€")
        print("- ê²€ìƒ‰ í’ˆì§ˆ: ìƒìœ„ 2-3ê°œ ì²­í¬ í•„í„°ë§ìœ¼ë¡œ ë…¸ì´ì¦ˆ ê°ì†Œ")
        print("- ì¿¼ë¦¬ ì´í•´: LLM ê¸°ë°˜ í™•ì¥ìœ¼ë¡œ ì˜ë„ íŒŒì•… í–¥ìƒ")
        print("- ì¬ìˆœìœ„í™”: ì •ìˆ˜ì²˜ë¦¬ ë„ë©”ì¸ íŠ¹í™”ë¡œ ì •í™•ì„± ì¦ê°€")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”.")
    
    return 0 if success else 1

if __name__ == "__main__":
    exit(main())
