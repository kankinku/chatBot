"""
Vector Retriever

ì„ë² ë”© ë²¡í„° ê¸°ë°˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê²€ìƒ‰.
FAISS ë˜ëŠ” NumPy ë°±ì—”ë“œ ì§€ì›.
"""

from __future__ import annotations

from pathlib import Path
from typing import List, Tuple, Optional

import numpy as np

from modules.core.types import Chunk
from modules.core.logger import get_logger
from modules.core.exceptions import VectorStoreNotFoundError, EmbeddingError
from modules.embedding.base_embedder import BaseEmbedder

logger = get_logger(__name__)


class VectorRetriever:
    """ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰"""
    
    def __init__(
        self,
        chunks: List[Chunk],
        embedder: BaseEmbedder,
        index_dir: Optional[str] = None,
        backend: str = "hnsw",  # "faiss", "hnsw", or "simple"
        use_gpu: bool = True,  # GPU ê°€ì† ê°•ì œ í™œì„±í™”
    ):
        """
        Args:
            chunks: ì²­í¬ ë¦¬ìŠ¤íŠ¸
            embedder: ì„ë² ë”
            index_dir: ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ (FAISS ì‚¬ìš© ì‹œ)
            backend: ë°±ì—”ë“œ ("faiss" or "simple")
            use_gpu: GPU ê°€ì† ì‚¬ìš© ì—¬ë¶€
        """
        self.chunks = chunks
        self.embedder = embedder
        self.index_dir = index_dir
        self.backend = backend
        self.use_gpu = use_gpu
        
        logger.info("VectorRetriever initializing",
                   num_chunks=len(chunks),
                   backend=backend,
                   embedding_dim=embedder.dim)
        
        # ì¸ë±ìŠ¤ êµ¬ì¶•
        self._build_index()
        
        logger.info("VectorRetriever initialized")
    
    def _build_index(self) -> None:
        """ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶•"""
        if self.backend == "faiss":
            self._build_faiss_index()
        elif self.backend == "hnsw":
            self._build_hnsw_index()
        else:
            self._build_simple_index()
    
    def _build_simple_index(self) -> None:
        """ê°„ë‹¨í•œ numpy ê¸°ë°˜ ì¸ë±ìŠ¤"""
        logger.info("Building simple numpy index")
        
        # ëª¨ë“  ì²­í¬ ì„ë² ë”©
        texts = [chunk.text for chunk in self.chunks]
        
        try:
            self.vectors = self.embedder.embed_texts(texts)
            
            # ğŸš€ ìµœì í™” 1A: ë²¡í„°ë¥¼ ì •ê·œí™”í•˜ì—¬ ì €ì¥ (norm ê³„ì‚° ë¶ˆí•„ìš”!)
            norms = np.linalg.norm(self.vectors, axis=1, keepdims=True)
            self.vectors = self.vectors / (norms + 1e-9)
            # ì´ì œ self.vectorsëŠ” ì´ë¯¸ ì •ê·œí™”ë˜ì–´ ìˆìŒ (norm = 1)
            
            logger.info(f"Simple index built (normalized vectors)", shape=self.vectors.shape)
        
        except Exception as e:
            raise EmbeddingError(
                "Failed to build simple vector index",
                cause=e
            ) from e
    
    def _build_hnsw_index(self) -> None:
        """HNSW ì¸ë±ìŠ¤ êµ¬ì¶• (FAISSë³´ë‹¤ ë¹ ë¦„)"""
        try:
            import hnswlib
            
            logger.info("Building HNSW index")
            
            # ëª¨ë“  ì²­í¬ ì„ë² ë”©
            texts = [chunk.text for chunk in self.chunks]
            embeddings = self.embedder.embed_texts(texts)
            
            # HNSW ì¸ë±ìŠ¤ ìƒì„±
            dim = embeddings.shape[1]
            self.index = hnswlib.Index(space='cosine', dim=dim)
            
            # ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            self.index.init_index(
                max_elements=len(embeddings),
                ef_construction=200,  # êµ¬ì¶• ì‹œ ì •í™•ë„
                M=16  # ì—°ê²° ìˆ˜
            )
            
            # ë²¡í„° ì¶”ê°€
            self.index.add_items(embeddings)
            
            # ê²€ìƒ‰ ì‹œ ì •í™•ë„ ì„¤ì •
            self.index.set_ef(50)  # ê²€ìƒ‰ ì‹œ ì •í™•ë„
            
            self.dim = dim
            self.backend = "hnsw"
            
            logger.info(f"HNSW index built successfully", 
                       dim=dim, 
                       num_vectors=len(embeddings))
        
        except ImportError as e:
            logger.warning("HNSW not available, falling back to simple index", 
                         error=str(e))
            self._build_simple_index()
        
        except Exception as e:
            logger.error("Failed to build HNSW index, falling back to simple index", 
                        error=str(e), exc_info=True)
            self._build_simple_index()
    
    def _build_faiss_index(self) -> None:
        """FAISS ì¸ë±ìŠ¤ êµ¬ì¶•/ë¡œë“œ (GPU ê°€ì† ì§€ì›)"""
        if not self.index_dir:
            # ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
            self.index_dir = "vector_store"
            logger.info(f"Auto-creating index directory: {self.index_dir}")
        
        index_path = Path(self.index_dir) / "index.faiss"
        meta_path = Path(self.index_dir) / "meta.json"
        
        # ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(self.index_dir).mkdir(parents=True, exist_ok=True)
        
        if not (index_path.exists() and meta_path.exists()):
            # ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
            logger.info(f"FAISS index not found, creating new index at {index_path}")
            self._create_faiss_index(index_path, meta_path)
            return
        
        try:
            import faiss
            import json
            
            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
            cpu_index = faiss.read_index(str(index_path))
            
            # GPU ê°€ì† í™œì„±í™”
            if self.use_gpu and faiss.get_num_gpus() > 0:
                try:
                    gpu_res = faiss.StandardGpuResources()
                    self.index = faiss.index_cpu_to_gpu(gpu_res, 0, cpu_index)
                    logger.info("FAISS GPU index loaded successfully")
                except Exception as gpu_e:
                    logger.warning(f"GPU FAISS failed, using CPU: {gpu_e}")
                    self.index = cpu_index
            else:
                self.index = cpu_index
                logger.info("FAISS CPU index loaded")
            
            # ë©”íƒ€ ì •ë³´ ë¡œë“œ
            with open(meta_path, "r") as f:
                meta = json.load(f)
                self.dim = meta.get("dim", self.embedder.dim)
            
            self.backend = "faiss"
            logger.info("FAISS index loaded", dim=self.dim)
        
        except ImportError:
            logger.warning("FAISS not available, falling back to simple index")
            self._build_simple_index()
        
        except Exception as e:
            logger.error(f"Failed to load FAISS index: {e}", exc_info=True)
            logger.info("Creating new FAISS index...")
            self._create_faiss_index(index_path, meta_path)
    
    def _create_faiss_index(self, index_path: Path, meta_path: Path) -> None:
        """ìƒˆë¡œìš´ FAISS ì¸ë±ìŠ¤ ìƒì„±"""
        try:
            # FAISS import ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ëª¨ë“  ì˜¤ë¥˜ í¬ì°©
            try:
                import faiss
                import json
            except (ImportError, ModuleNotFoundError, AttributeError) as import_error:
                logger.warning("FAISS import failed, falling back to simple index", 
                             error=str(import_error))
                self._build_simple_index()
                return
            
            logger.info("Creating FAISS index...")
            
            # ëª¨ë“  ì²­í¬ ì„ë² ë”© ìƒì„±
            embeddings = []
            for i, chunk in enumerate(self.chunks):
                if i % 100 == 0:
                    logger.info(f"Embedding progress: {i}/{len(self.chunks)}")
                
                embedding = self.embedder.embed_query(chunk.text)
                embeddings.append(embedding)
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            embeddings_array = np.array(embeddings).astype('float32')
            
            # FAISS ì¸ë±ìŠ¤ ìƒì„±
            dim = embeddings_array.shape[1]
            index = faiss.IndexFlatIP(dim)  # Inner Product (cosine similarity)
            
            # ì •ê·œí™” (cosine similarityë¥¼ ìœ„í•´)
            faiss.normalize_L2(embeddings_array)
            
            # ì¸ë±ìŠ¤ì— ë²¡í„° ì¶”ê°€
            index.add(embeddings_array)
            
            # ì¸ë±ìŠ¤ ì €ì¥
            faiss.write_index(index, str(index_path))
            
            # ë©”íƒ€ ì •ë³´ ì €ì¥
            meta = {
                "dim": dim,
                "num_vectors": len(embeddings),
                "index_type": "IndexFlatIP"
            }
            with open(meta_path, "w") as f:
                json.dump(meta, f)
            
            self.index = index
            self.dim = dim
            self.backend = "faiss"
            
            logger.info("FAISS index created successfully", 
                       dim=dim, 
                       num_vectors=len(embeddings))
        
        except ImportError as e:
            logger.warning("FAISS not available, falling back to simple index", 
                         error=str(e))
            self._build_simple_index()
        
        except Exception as e:
            logger.error("Failed to create FAISS index, falling back to simple index", 
                        error=str(e), exc_info=True)
            self._build_simple_index()
    
    def _build_gpu_faiss_index(self) -> None:
        """GPU ê°€ì† FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
        try:
            import faiss
            
            # GPU ë¦¬ì†ŒìŠ¤ ìƒì„±
            self.gpu_res = faiss.StandardGpuResources()
            
            # CPU ì¸ë±ìŠ¤ë¥¼ GPUë¡œ ì „í™˜
            cpu_index = faiss.read_index(str(Path(self.index_dir) / "index.faiss"))
            self.index = faiss.index_cpu_to_gpu(self.gpu_res, 0, cpu_index)
            
            logger.info("FAISS GPU index created successfully")
            
        except Exception as e:
            logger.warning(f"GPU FAISS failed, falling back to CPU: {e}")
            self._build_cpu_faiss_index()
    
    def _build_cpu_faiss_index(self) -> None:
        """CPU FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
        try:
            import faiss
            
            # CPU ì¸ë±ìŠ¤ ë¡œë“œ
            index_path = Path(self.index_dir) / "index.faiss"
            self.index = faiss.read_index(str(index_path))
            
            logger.info("FAISS CPU index loaded successfully")
            
        except Exception as e:
            logger.error(f"CPU FAISS failed: {e}")
            raise
    
    def search(
        self,
        query: str,
        top_k: int = 50,
    ) -> List[Tuple[int, float]]:
        """
        ë²¡í„° ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            
        Returns:
            [(ì²­í¬ ì¸ë±ìŠ¤, ìœ ì‚¬ë„), ...] ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_vec = self.embedder.embed_query(query)
            
            if self.backend == "faiss" and hasattr(self, 'index'):
                return self._search_faiss(query_vec, top_k)
            elif self.backend == "hnsw" and hasattr(self, 'index'):
                return self._search_hnsw(query_vec, top_k)
            else:
                return self._search_simple(query_vec, top_k)
        
        except Exception as e:
            logger.error(f"Vector search failed: {e}", exc_info=True)
            return []
    
    def _search_simple(
        self,
        query_vec: np.ndarray,
        top_k: int,
    ) -> List[Tuple[int, float]]:
        """ê°„ë‹¨í•œ numpy ê¸°ë°˜ ê²€ìƒ‰"""
        if not hasattr(self, 'vectors'):
            return []
        
        # ğŸš€ ìµœì í™” 1B: ì •ê·œí™”ëœ ë²¡í„° ì‚¬ìš© (dot productë§Œìœ¼ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„!)
        query_normalized = query_vec / (np.linalg.norm(query_vec) + 1e-9)
        similarities = np.dot(self.vectors, query_normalized)
        # ë‘ ë²¡í„° ëª¨ë‘ ì •ê·œí™”ë˜ì–´ ìˆìœ¼ë©´: dot(a, b) = cosine_similarity(a, b)
        
        # ìƒìœ„ kê°œ ì„ íƒ
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        result = [
            (int(idx), float(similarities[idx]))
            for idx in top_indices
        ]
        
        logger.debug(f"Simple vector search completed",
                    results=len(result),
                    top_score=result[0][1] if result else 0.0)
        
        return result
    
    def _search_hnsw(
        self,
        query_vec: np.ndarray,
        top_k: int,
    ) -> List[Tuple[int, float]]:
        """HNSW ê¸°ë°˜ ê²€ìƒ‰ (ë§¤ìš° ë¹ ë¦„)"""
        try:
            # HNSW ê²€ìƒ‰
            indices, distances = self.index.knn_query(query_vec, k=top_k)
            
            # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (HNSWëŠ” ê±°ë¦¬ ë°˜í™˜)
            similarities = 1.0 - distances[0]  # ì½”ì‚¬ì¸ ê±°ë¦¬ â†’ ìœ ì‚¬ë„
            
            result = [
                (int(idx), float(sim))
                for idx, sim in zip(indices[0], similarities)
            ]
            
            logger.debug(f"HNSW search completed",
                        results=len(result),
                        top_score=result[0][1] if result else 0.0)
            
            return result
        
        except Exception as e:
            logger.error(f"HNSW search failed: {e}", exc_info=True)
            return []
    
    def _search_faiss(
        self,
        query_vec: np.ndarray,
        top_k: int,
    ) -> List[Tuple[int, float]]:
        """FAISS ê¸°ë°˜ ê²€ìƒ‰"""
        query_vec = query_vec.reshape(1, -1).astype('float32')
        
        # FAISS ê²€ìƒ‰
        D, I = self.index.search(query_vec, top_k)
        
        result = [
            (int(idx), float(score))
            for idx, score in zip(I[0], D[0])
            if idx >= 0 and idx < len(self.chunks)
        ]
        
        logger.debug(f"FAISS vector search completed",
                    results=len(result),
                    top_score=result[0][1] if result else 0.0)
        
        return result

