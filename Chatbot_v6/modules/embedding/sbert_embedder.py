"""
SBERT Embedder

Sentence-BERT ëª¨ë¸ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”©.
ë°°ì¹˜ ì²˜ë¦¬, ì •ê·œí™”, LRU ìºì‹± ì§€ì› (ì¿¼ë¦¬ 1024ê°œ).
"""

from __future__ import annotations

from typing import List, Optional
from functools import lru_cache

import numpy as np

from .base_embedder import BaseEmbedder
from config.model_config import EmbeddingModelConfig
from modules.core.exceptions import EmbeddingModelLoadError, EmbeddingGenerationError, EmbeddingDimensionMismatch
from modules.core.logger import get_logger

logger = get_logger(__name__)


class SBERTEmbedder(BaseEmbedder):
    """Sentence-BERT ê¸°ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
    
    def __init__(self, config: Optional[EmbeddingModelConfig] = None):
        """
        Args:
            config: ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        """
        self.config = config or EmbeddingModelConfig()
        self._model = None
        self._dim = None
        self._device = None
        
        logger.info("SBERTEmbedder initializing", 
                   model=self.config.model_name,
                   device=self.config.device)
        
        self._load_model()
    
    def _load_model(self) -> None:
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            from sentence_transformers import SentenceTransformer
            import torch
            
            # Device ê²°ì • (GPU ê°•ì œ ì‚¬ìš©)
            if self.config.device == "auto" or self.config.device == "cpu":
                device = "cuda" if torch.cuda.is_available() else "cpu"
            else:
                device = self.config.device
            
            self._device = device
            
            # ëª¨ë¸ ë¡œë“œ
            self._model = SentenceTransformer(
                self.config.model_name,
                device=device
            )
            
            self._dim = self._model.get_sentence_embedding_dimension()
            
            logger.info("SBERT model loaded successfully",
                       model=self.config.model_name,
                       device=device,
                       dimension=self._dim)
        
        except ImportError as e:
            raise EmbeddingModelLoadError(
                self.config.model_name,
                cause=ImportError(
                    "sentence-transformers not installed. "
                    "Run: pip install sentence-transformers"
                )
            ) from e
        
        except Exception as e:
            raise EmbeddingModelLoadError(
                self.config.model_name,
                cause=e
            ) from e
    
    def embed_texts(self, texts: List[str]) -> np.ndarray:
        """
        ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©
        
        Args:
            texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì„ë² ë”© ë²¡í„° ë°°ì—´ (shape: [len(texts), dim])
            
        Raises:
            EmbeddingGenerationError: ì„ë² ë”© ìƒì„± ì‹¤íŒ¨
        """
        if not texts:
            return np.array([]).reshape(0, self._dim)
        
        try:
            logger.debug(f"Embedding {len(texts)} texts")
            
            embeddings = self._model.encode(
                texts,
                batch_size=self.config.batch_size,
                convert_to_numpy=True,
                normalize_embeddings=self.config.normalize_embeddings,
                show_progress_bar=self.config.show_progress_bar,
            )
            
            result = embeddings.astype("float32")
            
            logger.debug(f"Embeddings generated",
                        count=len(texts),
                        shape=result.shape)
            
            return result
        
        except Exception as e:
            raise EmbeddingGenerationError(
                text_sample=texts[0] if texts else "",
                cause=e
            ) from e
    
    # ğŸš€ ìµœì í™” 7: ì¿¼ë¦¬ ì„ë² ë”© ìºì‹± (ë™ì¼ ì¿¼ë¦¬ ì¬ì‚¬ìš©)
    @lru_cache(maxsize=1024)
    def _cached_embed(self, text: str) -> tuple:
        """ìºì‹± ê°€ëŠ¥í•œ ì„ë² ë”© (íŠœí”Œë¡œ ë°˜í™˜)"""
        embeddings = self.embed_texts([text])
        # NumPy ë°°ì—´ì€ ìºì‹± ë¶ˆê°€ì´ë¯€ë¡œ íŠœí”Œë¡œ ë³€í™˜
        return tuple(embeddings[0].astype("float32").tolist())
    
    def embed_query(self, text: str) -> np.ndarray:
        """
        ë‹¨ì¼ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©
        
        Args:
            text: ì¿¼ë¦¬ í…ìŠ¤íŠ¸
            
        Returns:
            ì„ë² ë”© ë²¡í„° (shape: [dim])
            
        Raises:
            EmbeddingGenerationError: ì„ë² ë”© ìƒì„± ì‹¤íŒ¨
        """
        if not text:
            raise EmbeddingGenerationError("Empty query text")
        
        try:
            # ìºì‹œëœ ì„ë² ë”© ì‚¬ìš©
            result_tuple = self._cached_embed(text)
            result = np.array(result_tuple, dtype="float32")
            
            return result
        
        except Exception as e:
            raise EmbeddingGenerationError(
                text_sample=text[:100],
                cause=e
            ) from e
    
    @property
    def dim(self) -> int:
        """ì„ë² ë”© ì°¨ì›"""
        return int(self._dim)
    
    @property
    def model_name(self) -> str:
        """ëª¨ë¸ ì´ë¦„"""
        return self.config.model_name
    
    def __del__(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            if hasattr(self, '_model') and self._model is not None:
                # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                except Exception as e:
                    # GPU ì •ë¦¬ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
                    logger.debug("GPU cache cleanup failed (non-critical)", error=str(e))
                
                # ëª¨ë¸ ì°¸ì¡° í•´ì œ
                del self._model
                self._model = None
                
                logger.debug("SBERT model cleaned up")
        except Exception as e:
            # ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨ëŠ” ì‹¬ê°í•œ ë¬¸ì œê°€ ì•„ë‹ˆë¯€ë¡œ debug ë ˆë²¨ë¡œ ë¡œê¹…
            logger.debug("Model cleanup failed (non-critical)", error=str(e), error_type=type(e).__name__)

